<GuideStepper.Step
  id="phase-1"
  number={1}
  title="Parity Translation"
  summary="Translate your existing dashboard's SQL or ORM query directly to ClickHouse SQL and prove output parity."
>
    <GuideStepper.WhatYouNeed>
      - A subdirectory in `<PROJECT_ROOT>/context/dashboard-migration/*/` for your component
      - The API specification for the endpoint
      - The existing backend endpoint handler (e.g. Express route, Fastify handler) that serves the dashboard data
      - The OLTP query file(s) that the handler calls (e.g. SQL builder, ORM query, raw query function)
      - A command to run your existing OLTP backend to capture test data
    </GuideStepper.WhatYouNeed>
    <GuideStepper.WhatYouGet>
      - A ClickHouse parity query that preserves the existing API contract and output semantics
      - Replayable parity test cases with expected vs actual diff evidence
    </GuideStepper.WhatYouGet>

<GuideStepper.Prompt>
Translate the provided Postgres or ORM endpoint query into ClickHouse SQL using MooseStack `sql` tagged template literal and prove parity against test cases from the existing OLTP system.

Path resolution requirements (run first):

1. Find the Moose project root (`<PROJECT_ROOT>`) by locating `moose.config.toml`.
2. Determine the project package name (`<PROJECT_PACKAGE>`) from `<PROJECT_ROOT>/package.json` (`name`) when package-based imports are needed.
3. Read `source_dir` from `moose.config.toml` and set `<SOURCE_DIR>` to that value (default to `app` if `source_dir` is not set).
4. Use `<PROJECT_ROOT>/<SOURCE_DIR>/...` for code paths and `<PROJECT_ROOT>/context/...` for migration artifacts.
5. Do not hardcode `moosestack/` or `app/` in resolved paths.

Rules:

1. Validate all required inputs once at start and list any missing inputs.
2. Preserve current API contract and output semantics exactly.
3. Before writing ClickHouse SQL, extract and document the OLTP query semantics in the TypeScript file that contains the ClickHouse translation (source tables + joins, filters, parameter defaults, group-by/aggregations, and edge cases).
4. Do not fabricate test case data, expected outputs, or verification evidence.
5. If any test case comparison fails, mark FAIL, report root cause, fix, and re-run.
6. Iterate on the query until all test cases pass.
7. Do not mark PASS until all test case diffs are empty.

Required inputs:

- The API specification for the existing OLTP endpoint
- Source code for the existing backend endpoint handler (e.g. Express route, Fastify handler) that serves the dashboard data
- The OLTP query file(s) that the handler calls (e.g. SQL builder, ORM query, raw query function)

Required outputs:

- 2-5 test case files under `<PROJECT_ROOT>/context/dashboard-migration/<COMPONENT_NAME>/test-cases/` with the exact JSON response from the OLTP endpoint for each test case.
- `<PROJECT_ROOT>/<SOURCE_DIR>/queries/<COMPONENT_NAME>-olap-translation.ts` with the ClickHouse translation of the OLTP query.
- Updated `context-map.md` with the file path to the file that contains the ClickHouse translation of the OLTP query.
- Test case verification evidence (`expected.json`, `actual.json`, `diff`)
</GuideStepper.Prompt>

<GuideStepper.Checkpoint
  id="phase-1-capture-test-cases"
  title="Capture 2-5 representative test cases"
>
Goal: capture 2–5 representative test cases from the **existing** OLTP endpoint. These test cases will be used to validate correctness of the translated ClickHouse query you will write in the next checkpoint.

Steps:

1. Identify 2–5 representative requests that exercise different filters, time ranges, and edge cases (e.g. empty results, large result sets, boundary dates).
2. Run each request against the **live OLTP endpoint** and capture the exact response.
3. For each test case, create a file: `<PROJECT_ROOT>/context/dashboard-migration/<COMPONENT_NAME>/test-cases/0N-<TEST_CASE_NAME>.md`.
4. Each file must include:
   - the `curl` command (GET or POST)
   - the **verbatim** JSON response — this must come from actually calling the running endpoint, not from approximation
5. Choose requests that cover a reasonable recent time window (e.g. last 7–30 days) so parity validation uses a consistent, representative slice.

For components that read `EXTERNALLY_MANAGED` tables, local data coverage is controlled in `moose.config.toml` via `[dev.remote_clickhouse]` and `[dev.externally_managed.tables]` (especially `sample_size`). Set this sample size to a reasonable value for the test cases you are capturing.

Copy the provided test case template (path: `context/migrations/test-case-template.md`) to create the test case files:

```bash
cp <PROJECT_ROOT>/context/migrations/test-case-template.md <PROJECT_ROOT>/context/dashboard-migration/<COMPONENT_NAME>/test-cases/0N-<TEST_CASE_NAME>.md
```

This checkpoint is complete when 2–5 test case files exist under `test-cases/`, each with a runnable curl command and the actual JSON response from the OLTP endpoint. Record the file paths in `context-map.md`.

</GuideStepper.Checkpoint>

<GuideStepper.Checkpoint
  id="phase-1-clickhouse-parity-function"
  title="ClickHouse parity function"
>
Goal: write a direct translation of the OLTP query into ClickHouse SQL that returns the exact same response shape.

Steps:

1. Locate the SQL query (or stored procedure) that powers the existing endpoint and record OLTP semantics in `context-map.md` under Phase 1 Notes:
   - Source tables and join conditions (including join type)
   - Filter clauses (including implicit tenancy, soft-delete, or RBAC filters)
   - Parameter substitution rules and defaults
   - Group-by / aggregation logic
   - Edge cases (null handling, division by zero, missing rows)
2. Create `<PROJECT_ROOT>/<SOURCE_DIR>/queries/<COMPONENT_NAME>-olap-translation.ts`.
3. Write a function that:
   - accepts the exact same parameters as the existing handler/query logic
   - builds the translated query using the `sql` tagged template literal
   - executes via the Moose ClickHouse client against local `moose dev`
4. Preserve column names, types, and ordering exactly. Add explicit `ORDER BY` and casts where needed.
5. Call out any ClickHouse-specific differences (null handling, decimal precision, timestamp bucketing) as comments in the code.
6. Record the file path in `context-map.md`.

Refer to the [ClickHouse SQL reference](https://clickhouse.com/docs/en/sql-reference) as you translate.

Example (adapt to your component — do not copy names literally):

```ts filename="<PROJECT_ROOT>/<SOURCE_DIR>/queries/<COMPONENT_NAME>-olap-translation.ts" copy
import { sql, MooseClient } from "@514labs/moose-lib";
import { Orders } from "./models/Orders.model";

interface ParityInput {
  merchantId: string;
  startDate: string;
  endDate: string;
}

interface ParityRow {
  day: string;
  fulfilled: number;
  total: number;
}

export async function runParity(
  params: ParityInput,
  client: MooseClient,
): Promise<ParityRow[]> {
  const statement = sql`
    SELECT
      toDate(order_ts) AS day,
      sumIf(1, status = 'fulfilled') AS fulfilled,
      count() AS total
    FROM ${Orders}
    WHERE merchant_id = ${params.merchantId}
      AND order_ts >= toDateTime(${params.startDate})
      AND order_ts < toDateTime(${params.endDate})
    GROUP BY day
    ORDER BY day ASC
  `;

  return client.query<ParityRow>(statement);
}
```

**Done when:** `context-map.md` contains complete OLTP semantics, the parity function compiles and runs against local `moose dev`, and the translation file path is recorded in `context-map.md`.

</GuideStepper.Checkpoint>

<GuideStepper.Checkpoint
  id="phase-1-verification"
  title="Verification"
>
Goal: prove the parity function returns the exact same JSON as the OLTP endpoint for every test case.

Iteration rule: treat Phase 1 as a red/green loop. If any `diff` is non-empty, revise the ClickHouse translation, re-run verification, and repeat until every test case diff is empty.

Steps:

1. For each Checkpoint 1 test case, call the parity function with the same parameters and capture the output:

   Run this command from `<PROJECT_ROOT>` (or whichever directory contains your `tsconfig.json` and `node_modules`). The inline `tsx` script uses a relative import (`./<SOURCE_DIR>/queries/<component>-olap-translation`) and `getMooseUtils()` from `@514labs/moose-lib`, so it depends on your project's TypeScript/module resolution context. If your query file lives elsewhere, adjust the import path accordingly so both `runParity` and `getMooseUtils` resolve.

```bash
pnpm tsx -e "
  import { runParity } from './<SOURCE_DIR>/queries/<COMPONENT_NAME>-olap-translation';
  import { getMooseUtils } from '@514labs/moose-lib';
  const { client } = await getMooseUtils();
  const result = await runParity(
    { /* same params as the test case curl */ },
    client,
  );
  console.log(JSON.stringify(result));
" | jq -S '.' > actual.json
```

2. Extract the expected response from the test case file:

````bash
awk 'f{print} /^```json/{f=1; next} /^```$/{if(f){exit}}' \
  <PROJECT_ROOT>/context/dashboard-migration/<COMPONENT_NAME>/test-cases/0N-<TEST_CASE_NAME>.md \
  | jq -S '.' > expected.json
````

3. Diff:

```bash
diff expected.json actual.json
```

4. If `diff` is non-empty, debug and fix the translation:
   - Column names (case-sensitive in ClickHouse)
   - Data types (timestamps, decimals, integers vs floats)
   - Sort order (add explicit `ORDER BY` if needed)
   - Missing rows or availability mismatch for the selected test-case window:
     - confirm local/source data coverage
     - for `EXTERNALLY_MANAGED` tables, configure local mirrors in `moose.config.toml` (`[dev.remote_clickhouse]`, `[dev.externally_managed.tables]`, `sample_size`) and restart `moose dev`
     - adjust the test window only if needed
5. Re-run Steps 1-4 for the same test case until `diff` produces no output.
6. Repeat Steps 1-5 for every recorded test case.

**Done when:** `diff` produces no output for every test case. Once all test cases pass, Phase 1 is complete — proceed to Phase 2.

</GuideStepper.Checkpoint>
</GuideStepper.Step>
