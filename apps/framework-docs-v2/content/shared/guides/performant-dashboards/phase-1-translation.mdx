<GuideStepper.Step
  id="phase-1"
  number={1}
  title="Parity translation (OLTP → ClickHouse parity function)"
  summary="Translate your existing endpoint logic directly to ClickHouse and prove output parity."
>
    <GuideStepper.WhatYouNeed>
      - `moosestack/context/dashboard-migration/<component>/` — the context directory for this component
      - The API specification for the endpoint
      - Your existing backend endpoint handler (e.g. Express route, Fastify handler) that serves the dashboard data
      - The OLTP query file(s) that the handler calls (e.g. SQL builder, ORM query, raw query function)
    </GuideStepper.WhatYouNeed>
    <GuideStepper.WhatYouGet>
      - A ClickHouse parity query that preserves the existing API contract
      - Replayable parity test cases with expected vs actual diff evidence
      - A documented Phase 1 context map for downstream optimization work
    </GuideStepper.WhatYouGet>

<GuideStepper.Prompt>
Translate the provided Postgres or ORM endpoint query into ClickHouse SQL using MooseStack `sql` tagged template literal and prove parity against test cases from the existing OLTP endpoint.

Rules:

1. Validate required inputs once at start and list any missing input.
2. Preserve current API contract and output semantics exactly.
3. Record ambiguities and assumptions as an inline comment in the ClickHouse translation file.
4. Do not fabricate test case data, expected outputs, or verification evidence.
5. If any test case comparison fails, mark FAIL, report root cause, fix, and re-run.
6. Do not mark PASS until all test case diffs are empty.

Required inputs:

- The API specification for the existing OLTP endpoint
- Source code for the existing backend endpoint handler (e.g. Express route, Fastify handler) that serves the dashboard data
- The OLTP query file(s) that the handler calls (e.g. SQL builder, ORM query, raw query function)

Required outputs:

- `moosestack/app/queries/<COMPONENT_NAME>-olap-translation.ts` with the ClickHouse translation of the OLTP query.
- Updated `context-map.md` with the file path to the file that contains the ClickHouse translation of the OLTP query.
- 2–5 test case files under `moosestack/context/dashboard-migration/<COMPONENT_NAME>/test-cases/` with the exact JSON response from the OLTP endpoint for each test case.
- Test case verification evidence (`expected.json`, `actual.json`, `diff`)
</GuideStepper.Prompt>

<GuideStepper.Checkpoint
  id="phase-1-capture-test-cases"
  title="Capture test cases"
>
Goal: capture 2–5 replayable test cases from the **existing** OLTP endpoint. These test cases will be used to validate correctness of the translated ClickHouse query you will write in the next checkpoint.

Steps:

1. Identify 2–5 representative requests that exercise different filters, time ranges, and edge cases (e.g. empty results, large result sets, boundary dates).
2. Run each request against the **live OLTP endpoint** and capture the exact response.
3. For each test case, create a file: `moosestack/context/dashboard-migration/<COMPONENT_NAME>/test-cases/0N-<TEST_CASE_NAME>.md`.
4. Each file must include:
   - the `curl` command (GET or POST)
   - the **verbatim** JSON response — this must come from actually calling the running endpoint, not from approximation
5. Choose requests that cover a reasonable recent time window (e.g. last 7–30 days). You will seed your local ClickHouse to match this window after identifying the source tables in Checkpoint 2.

Copy the provided test case template (path: `context/migrations/test-case-template.md`) to create the test case files:

```bash
cp context/migrations/test-case-template.md moosestack/context/dashboard-migration/<COMPONENT_NAME>/test-cases/0N-<TEST_CASE_NAME>.md
```

This checkpoint is complete when 2–5 test case files exist under `test-cases/`, each with a runnable curl command and the actual JSON response from the OLTP endpoint. Record the file paths in `context-map.md`.

</GuideStepper.Checkpoint>

<GuideStepper.Checkpoint
  id="phase-1-oltp-semantics"
  title="OLTP semantics"
>
Goal: extract the query logic from the existing endpoint so you have a precise spec to translate.

Steps:

1. Locate the SQL query or stored procedure that powers the existing endpoint (typically in the backend handler or a database layer).
2. Document:
   - Source tables and join conditions (including join type)
   - Filter clauses (including implicit tenancy, soft-delete, or RBAC filters)
   - Parameter substitution rules and defaults
   - Group-by / aggregation logic
   - Edge cases (null handling, division by zero, missing rows)
3. Record these findings in `context-map.md` under Phase 1 Notes.

**Done when:** `context-map.md` lists every source table, the join graph, all filter/aggregation logic, and any edge cases. You should be able to write the ClickHouse translation from this spec alone.

</GuideStepper.Checkpoint>

<GuideStepper.Checkpoint
  id="phase-1-seed-local-clickhouse"
  title="Seed local ClickHouse"
>
Goal: seed your local ClickHouse with enough production data to fully cover the test cases from Checkpoint 1. You now know the source tables (from Checkpoint 2) and the time windows and filter values (from Checkpoint 1).

Prerequisites:

- Dev server is running (`moose dev`)
- Production ClickHouse HTTPS connection string is exported:

```shell
export CLICKHOUSE_PROD_URL="<YOUR_HTTPS_CONNECTION_STRING>"
```

The connection string should start with `https://` (for example, `https://username:password@host:8443/database`).

Steps:

1. For each source table from Checkpoint 2, generate and run a seed command that covers the test case time windows:

```shell
moose seed clickhouse \
  --connection-string "$CLICKHOUSE_PROD_URL" \
  --table <TABLE_NAME> \
  --order-by '<TIMESTAMP_COLUMN> DESC' \
  --limit 100000
```

2. Verify the seeded data covers every test case:

```shell
moose query -q "SELECT min(<TIMESTAMP_COLUMN>), max(<TIMESTAMP_COLUMN>), count() FROM <TABLE_NAME> FINAL"
```

If any test case falls outside the seeded range, re-seed with a larger `--limit` or use `--all`.

**Done when:** every source table has local data that spans the time windows used in all Checkpoint 1 test cases.

</GuideStepper.Checkpoint>

<GuideStepper.Checkpoint
  id="phase-1-clickhouse-parity-function"
  title="ClickHouse parity function"
>
Goal: write a direct translation of the OLTP query into ClickHouse SQL that returns the exact same response shape.

Steps:

1. Create `moosestack/app/queries/<COMPONENT_NAME>-olap-translation.ts`.
2. Write a function that:
   - accepts the exact same parameters as the existing handler/query logic
   - builds the translated query using the `sql` tagged template literal
   - executes via the Moose ClickHouse client against local `moose dev`
3. Preserve column names, types, and ordering exactly. Add explicit `ORDER BY` and casts where needed.
4. Call out any ClickHouse-specific differences (null handling, decimal precision, timestamp bucketing) as comments in the code.
5. Record the file path in `context-map.md`.

Refer to the [ClickHouse SQL reference](https://clickhouse.com/docs/en/sql-reference) as you translate.

Example (adapt to your component — do not copy names literally):

```ts filename="moosestack/app/queries/<COMPONENT_NAME>-olap-translation.ts" copy
import { sql, MooseClient } from "@514labs/moose-lib";
import { Orders } from "./models/Orders.model";

interface ParityInput {
  merchantId: string;
  startDate: string;
  endDate: string;
}

interface ParityRow {
  day: string;
  fulfilled: number;
  total: number;
}

export async function runParity(
  params: ParityInput,
  client: MooseClient,
): Promise<ParityRow[]> {
  const statement = sql`
    SELECT
      toDate(order_ts) AS day,
      sumIf(1, status = 'fulfilled') AS fulfilled,
      count() AS total
    FROM ${Orders}
    WHERE merchant_id = ${params.merchantId}
      AND order_ts >= toDateTime(${params.startDate})
      AND order_ts < toDateTime(${params.endDate})
    GROUP BY day
    ORDER BY day ASC
  `;

  return client.query<ParityRow>(statement);
}
```

**Done when:** the parity function compiles, runs against local `moose dev`, and returns results. The file path is recorded in `context-map.md`.

</GuideStepper.Checkpoint>

<GuideStepper.Checkpoint
  id="phase-1-verification"
  title="Verification"
>
Goal: prove the parity function returns the exact same JSON as the OLTP endpoint for every test case.

Steps:

1. For each Checkpoint 1 test case, call the parity function with the same parameters and capture the output:

   Run this command from your MooseStack project root (or whichever directory contains your `tsconfig.json` and `node_modules`). The inline `tsx` script uses a relative import (`./app/queries/<component>-olap-translation`) and `getMooseUtils()` from `@514labs/moose-lib`, so it depends on your project's TypeScript/module resolution context. If your query file lives elsewhere, adjust the import path accordingly so both `runParity` and `getMooseUtils` resolve.

```bash
pnpm tsx -e "
  import { runParity } from './app/queries/<COMPONENT_NAME>-olap-translation';
  import { getMooseUtils } from '@514labs/moose-lib';
  const { client } = await getMooseUtils();
  const result = await runParity(
    { /* same params as the test case curl */ },
    client,
  );
  console.log(JSON.stringify(result));
" | jq -S '.' > actual.json
```

2. Extract the expected response from the test case file:

````bash
awk 'f{print} /^```json/{f=1; next} /^```$/{if(f){exit}}' \
  moosestack/context/dashboard-migration/<COMPONENT_NAME>/test-cases/0N-<TEST_CASE_NAME>.md \
  | jq -S '.' > expected.json
````

3. Diff:

```bash
diff expected.json actual.json
```

4. If there are differences, check:
   - Column names (case-sensitive in ClickHouse)
   - Data types (timestamps, decimals, integers vs floats)
   - Sort order (add explicit `ORDER BY` if needed)
   - Missing rows (seed slice too small — re-seed with a larger `--limit`)

**Done when:** `diff` produces no output for every test case. Once all test cases pass, Phase 1 is complete — proceed to Phase 2.

</GuideStepper.Checkpoint>
</GuideStepper.Step>
