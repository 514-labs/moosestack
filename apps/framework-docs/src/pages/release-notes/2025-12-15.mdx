---
title: December 15, 2025
description: Release notes for December 15, 2025
---

import { Callout } from "@/components";

# December 15, 2025

<Callout type="info" title="Highlights">
* **New:** Display ClickHouse connection info during moose dev startup
* **New:** Added infrastructure map visualization to project overview
</Callout>



## ü¶å Moose

### New Features
- **Display ClickHouse connection info during moose dev startup**
  The moose dev command now displays ClickHouse connection URLs when starting local infrastructure, making it easier for developers to connect to their databases for debugging and data exploration. Connection details are shown with masked passwords for security.

- **Add comprehensive December 5, 2025 release notes**
  Published detailed release notes covering major new features including Kafka engine support, IcebergS3 integration, materialized columns, Fastify web app template, and Boreal database storage visualization. Includes bug fixes, performance improvements, and breaking changes that users need to know about.

- **Add JSON output option to plan command**
  The `moose plan` command now supports a `--json` flag that outputs the infrastructure plan in JSON format for programmatic use and automation. This enables users to integrate plan results into CI/CD pipelines, scripts, and other tooling. Also includes fixes for production deployments with Docker Compose dependencies.

  **Using moose plan --json for automated infrastructure planning**
  ```bash
  # Basic usage: Get plan output in JSON format
  moose plan --json
  
  # Use in CI/CD pipeline to check for changes
  PLAN_OUTPUT=$(moose plan --json)
  if echo "$PLAN_OUTPUT" | jq -e '.changes | length > 0' > /dev/null; then
    echo "Infrastructure changes detected:"
    echo "$PLAN_OUTPUT" | jq '.changes'
    # Proceed with deployment or approval workflow
  else
    echo "No infrastructure changes needed"
  fi
  
  # Parse specific change types for automation
  moose plan --json | jq -r '.changes[] | select(.operation == "CREATE") | .table_name'
  
  # Save plan to file for review or audit trail
  moose plan --json > infrastructure-plan.json
  
  # Compare with remote ClickHouse instance
  moose plan --json --clickhouse-url "clickhouse://user:pass@host:9000/db"
  
  # Use with remote Moose server
  moose plan --json --url "https://api.mymoose.app" --token "$MOOSE_TOKEN"
  ```
  
  Shows how to use the new --json flag with the moose plan command for programmatic access to infrastructure planning. Demonstrates integration with CI/CD pipelines, change detection, and automated workflows using jq for JSON processing.

- **Add support for VersionedCollapsingMergeTree and replicated variants**
  Added support for VersionedCollapsingMergeTree, CollapsingMergeTree, and their replicated variants in ClickHouse table engines. Users can now define data models that use these specialized merge tree engines for handling versioned data and collapsing operations, enabling more advanced data deduplication and versioning patterns in their streaming pipelines.

  **User Profile Tracking with VersionedCollapsingMergeTree**
  ```typescript
  import { Key } from "@514labs/moose-lib";
  
  // Define a data model using VersionedCollapsingMergeTree for user profile updates
  // This allows tracking profile changes over time with automatic deduplication
  export interface UserProfile {
    userId: Key<string>;
    email: string;
    name: string;
    lastLoginAt: Date;
    
    // Required fields for VersionedCollapsingMergeTree
    sign: number;    // 1 for insert, -1 for delete/update
    version: number; // Monotonically increasing version number
  }
  
  // Configure the table to use VersionedCollapsingMergeTree engine
  export default {
    tableName: "user_profiles",
    engine: {
      VersionedCollapsingMergeTree: {
        sign: "sign",     // Column name for the sign field
        ver: "version"    // Column name for the version field
      }
    },
    orderBy: ["userId", "version"], // Order by user ID and version
    primaryKey: ["userId"]
  };
  
  // Example usage in a streaming function
  export function processUserUpdate(oldProfile: UserProfile, newProfile: UserProfile) {
    return [
      // Mark old record for deletion
      { ...oldProfile, sign: -1 },
      // Insert new record
      { ...newProfile, sign: 1, version: oldProfile.version + 1 }
    ];
  }
  ```
  
  This example shows how to define a data model using VersionedCollapsingMergeTree engine in MooseStack. The engine automatically handles versioned data with deduplication, perfect for tracking changes to user profiles or other entities over time while maintaining query performance.

- **Add persistent volume support for Moose deployments**
  Moose deployments now support persistent volume mounts, allowing applications to store and access data that persists across pod restarts and redeployments. Users can configure storage volumes through the deployment configuration to maintain state for databases, file storage, or other persistent data needs.

  **Configure persistent volumes in Moose deployment**
  ```typescript
  // moose.config.ts - Configure persistent volumes for your Moose deployment
  import { MooseConfig } from "@514labs/moose-lib";
  
  export default {
    name: "analytics-pipeline",
    
    // Configure persistent storage for your data pipeline
    deployment: {
      resources: {
        // Mount persistent volumes for data storage
        volumeMounts: [
          {
            name: "user-data-storage",
            storageClassName: "fast-ssd",
            volumeName: "analytics-data-pv",
            storage: "100Gi",
            mountPath: "/app/data/users"
          },
          {
            name: "logs-storage", 
            storageClassName: "standard",
            volumeName: "logs-pv",
            storage: "50Gi",
            mountPath: "/app/logs"
          }
        ],
        pod: {
          cpu: "2",
          memory: "4Gi"
        },
        service: {
          replicas: 2
        }
      }
    }
  } satisfies MooseConfig;
  ```
  
  This example shows how to configure persistent volume mounts in a Moose deployment configuration. The volumes persist data across pod restarts, making it ideal for storing processed data files, logs, or maintaining state in data pipelines.

### Improvements
- Reorganized configuration documentation into dedicated sections: Split the large configuration documentation page into focused sections for each component (ClickHouse, Redis, Redpanda, Temporal, etc.). This makes it easier to find and understand configuration options for specific parts of your MooseStack project.
- Add web-apps filter option to moose ls command: The moose ls command now supports filtering by web-apps infrastructure type, allowing users to view web application components in their data pipeline alongside other infrastructure types like tables, streams, and ingestion endpoints.

### Bug Fixes
- Fix database engine detection for custom databases during migrations: Fixed an issue where tables in custom databases weren't properly matched during migrations, causing them to appear unmapped and potentially use stale engine information. This could lead to incorrect engine type detection (e.g., showing MergeTree instead of ReplicatedReplacingMergeTree) and migration issues for users with custom database configurations.
- Fix unnecessary table recreation when ClickHouse readonly settings change to defaults: Fixed an issue where ClickHouse tables would be unnecessarily recreated when readonly settings changed from None to their default values (e.g., index_granularity to 8192). This prevents disruptive table drops and recreations during deployments when no actual configuration changes occurred.
- Fix database name handling when loading infrastructure from JSON: Fixed an issue where the infrastructure map would not properly update database names and table IDs when loading from JSON files in production deployments. This ensures that table references and sync processes maintain correct database naming consistency, preventing potential deployment failures.
- Standardize db pull command flag from --connection-string to --clickhouse-url: The `moose db pull` command now uses `--clickhouse-url` instead of `--connection-string` for consistency with other CLI commands. The command also supports the `CLICKHOUSE_URL` environment variable as a fallback. This standardizes the interface and makes it easier to configure database connections across different commands.
- Fix TypeScript and Python clients inserting to correct database: Fixed a bug where TypeScript and Python OlapTable clients were not respecting per-table database configuration. Previously, clients would always connect to the global default database even when a table was configured with a specific database. Now clients properly use the table-specific database setting when specified, falling back to the global config when not set.
- Fix TTL operation ignoring and add ModifyTableTtl migration schema: Fixed a bug where TTL (Time To Live) operations weren't being properly ignored when specified, and added proper schema support for ModifyTableTtl migrations. This ensures TTL changes are handled correctly during table migrations and can be selectively ignored when needed. Also improved Kafka engine documentation with additional ClickHouse integration details.
- Fix Kafka-to-ClickHouse sync to respect custom database configuration: Fixed a bug where the Kafka-to-ClickHouse sync process ignored the table.database field in data model configurations, always using the default database instead. Now when users specify a custom database in their table configuration, the sync process correctly writes data to that database.

## üêª Boreal

### New Features
- **Added infrastructure map visualization to project overview**
  Users can now view an interactive infrastructure map on the project overview page that visualizes their data pipeline components and connections. This feature is currently available as an experimental feature and provides a visual representation of tables, views, APIs, workflows, and other infrastructure components in their MooseStack application.
  
  üì∏ *[Screenshot needed: Users can now view an interactive infrastructure map on the project overview page that visualizes their data pipeline components and connections. This feature is currently available as an experimental feature and provides a visual representation of tables, views, APIs, workflows, and other infrastructure components in their MooseStack application.]*

### Bug Fixes
- Fix deployment issues when starting from pull requests: Fixed an issue where deployments initiated from pull requests were failing to complete properly. This ensures that PR-based deployments now work reliably in the project management interface.
- Fix hosting telemetry crash: Fixed a crash in the hosting telemetry system that could cause application instability. This improves the reliability of the platform's monitoring and data collection capabilities.
- Fix first-time project deployments: Fixed an issue where first-time project deployments would fail due to an error when no previous production deployment existed. Users can now successfully deploy new projects without encountering deployment errors.
- Fixed deployment error handling when no production deploy exists: Improved deployment reliability by properly handling cases where no previous production deployment exists. This prevents deployment failures and provides better error tracking for project setup scenarios.
- Fixed deployment redeployment to maintain production status: Fixed an issue where redeploying a production deployment would incorrectly mark it as non-production, potentially causing confusion about which deployment is currently live. Also improved error handling when no production deployment is found.
- Fixed deployment status filtering to show correct production deployments: Fixed an issue where the deployment dashboard was using incorrect status filtering, which could cause production deployments to display incorrectly or not appear when they should. Users will now see accurate deployment status information in their project dashboard.
- Fixed deployment status retrieval for production environments: Fixed an issue where the system wasn't properly retrieving the current production deployment status. This ensures that deployment information is accurately displayed in the dashboard and prevents potential inconsistencies in deployment tracking.

## üì¶ infrastructure

### Improvements
- Increased deployment startup timeout to improve reliability: Extended deployment startup timeout from 3 minutes to 20 minutes to prevent deployment failures during slow image pulls or resource provisioning. This reduces failed deployments and improves overall platform reliability for users.


