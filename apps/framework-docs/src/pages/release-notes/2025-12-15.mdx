---
title: December 15, 2025
description: Release notes for December 15, 2025
---

import { Callout } from "@/components";

# December 15, 2025

<Callout type="info" title="Highlights">
* **New:** Display ClickHouse connection info during moose dev startup
* **New:** Added infrastructure map visualization to project overview
</Callout>



## ü¶å Moose

### New Features
- **Display ClickHouse connection info during moose dev startup**
  The moose dev command now displays ClickHouse connection URLs when starting local infrastructure, making it easier for developers to connect to their databases for debugging and data exploration. Connection details are shown with masked passwords for security.

- **Add comprehensive December 5, 2025 release notes**
  Published detailed release notes covering major new features including Kafka engine support, IcebergS3 integration, materialized columns, Fastify web app template, and Boreal database storage visualization. Includes bug fixes, performance improvements, and breaking changes that users need to know about.

- **Add persistent volume support for Moose deployments**
  Moose deployments now support persistent volume claims (PVCs) for data storage that persists across pod restarts and redeployments. Users can configure volume mounts through the deployment configuration to ensure data persistence for their applications.

  **Configure persistent volumes in Moose deployment**
  ```typescript
  // moose.config.ts - Configure persistent volumes for your Moose deployment
  import { MooseConfig } from "@514labs/moose-lib";
  
  export default {
    // Your standard Moose configuration
    project: "analytics-pipeline",
    
    // Deployment configuration with persistent volume support
    deployment: {
      // Resource configuration for your deployment
      resources: {
        pod: {
          cpu: "500m",
          memory: "1Gi"
        },
        service: {
          replicas: 2
        },
        // Configure persistent volumes for data that needs to survive pod restarts
        volumeMounts: [
          {
            name: "data-storage",
            storageClassName: "fast-ssd",
            volumeName: "analytics-data-pv",
            storage: "10Gi",
            mountPath: "/app/data" // Where the volume is mounted in your container
          },
          {
            name: "cache-storage", 
            storageClassName: "standard",
            volumeName: "analytics-cache-pv",
            storage: "5Gi",
            mountPath: "/app/cache" // Separate volume for cache data
          }
        ]
      }
    }
  } satisfies MooseConfig;
  ```
  
  This example shows how to configure persistent volume claims (PVCs) in a Moose deployment configuration. The volumes will persist data across pod restarts and redeployments, ensuring your analytics data and cache remain available even when the infrastructure is updated.

### Improvements
- Reorganized configuration documentation into dedicated sections: Split the large configuration documentation page into focused sections for each component (ClickHouse, Redis, Redpanda, Temporal, etc.). This makes it easier to find and understand specific configuration options for your MooseStack project.

### Bug Fixes
- Fix database engine detection for custom databases during migrations: Fixed an issue where tables in custom databases weren't properly matched during migrations, causing them to appear unmapped and potentially use stale engine information. This could lead to incorrect engine type detection (e.g., showing MergeTree instead of ReplicatedReplacingMergeTree) and migration issues for users with custom database configurations.
- Fix unnecessary table recreation when ClickHouse readonly settings change to defaults: Fixed an issue where ClickHouse tables would be unnecessarily recreated when readonly settings changed from None to their default values (e.g., index_granularity to 8192). This prevents disruptive table drops and recreations during deployments when no actual configuration changes occurred.
- Fix database name handling when loading infrastructure from JSON: Fixed an issue where the infrastructure map would not properly update database names and table IDs when loading from JSON files in production deployments. This ensures that table references and sync processes maintain correct database naming consistency, preventing potential deployment failures or data routing issues.
- Standardize db pull command flag from --connection-string to --clickhouse-url: The `moose db pull` command now uses `--clickhouse-url` instead of `--connection-string` for consistency with other CLI commands. The command also supports the `CLICKHOUSE_URL` environment variable as a fallback. This standardizes the interface and makes it easier to configure database connections across different commands.
- Fix TypeScript and Python clients inserting to correct database: Fixed a bug where TypeScript and Python OlapTable clients were not respecting per-table database configuration. Previously, clients would always connect to the global default database even when a table was configured with a specific database. Now clients properly use the table-specific database setting when specified, falling back to the global config when not set.
- Fix TTL operation ignoring and add ModifyTableTtl migration schema: Fixed a bug where TTL (Time To Live) operations weren't being properly ignored when specified, and added proper schema support for ModifyTableTtl migrations. This ensures TTL changes are handled correctly during table migrations and can be selectively ignored when needed. Also improved Kafka engine documentation with additional ClickHouse integration details.
- Fix Kafka-to-ClickHouse sync to respect custom database configuration: Fixed a bug where the Kafka-to-ClickHouse sync process ignored the table.database field in data model configurations, always using the default database instead. Now when users specify a custom database in their table configuration, the sync process correctly writes data to that database.

## üêª Boreal

### New Features
- **Added infrastructure map visualization to project overview**
  Users can now view an interactive infrastructure map on the project overview page that visualizes their data pipeline components and connections. This feature is currently available as an experimental feature and provides a visual representation of tables, views, APIs, workflows, and other infrastructure components in their MooseStack application.
  
  üì∏ *[Screenshot needed: Users can now view an interactive infrastructure map on the project overview page that visualizes their data pipeline components and connections. This feature is currently available as an experimental feature and provides a visual representation of tables, views, APIs, workflows, and other infrastructure components in their MooseStack application.]*

### Bug Fixes
- Fix deployment issues when starting from pull requests: Fixed an issue where deployments initiated from pull requests were failing to complete properly. This ensures that PR-based deployments now work reliably in the project management interface.
- Fix hosting telemetry crash: Fixed a crash in the hosting telemetry system that could cause application instability. This improves the reliability of the platform's monitoring and data collection capabilities.
- Fix first-time project deployments: Fixed an issue where first-time project deployments would fail due to an error when no previous production deployment existed. Users can now successfully deploy new projects without encountering deployment errors.
- Fixed deployment error handling when no production deploy exists: Improved deployment reliability by properly handling cases where no previous production deployment exists. This prevents deployment failures and provides better error tracking for project setup scenarios.
- Fixed deployment redeployment to maintain production status: Fixed an issue where redeploying a production deployment would incorrectly mark it as non-production, potentially causing confusion about which deployment is currently live. Also improved error handling when no production deployment is found.
- Fixed deployment status filtering to show correct production deployments: Fixed an issue where the deployment dashboard was using incorrect status filtering, which could cause production deployments to display incorrectly or not appear when they should. Users will now see accurate deployment status information in their project dashboard.
- Fixed deployment status retrieval for production environments: Fixed an issue where the system wasn't properly filtering deployed production environments, which could cause incorrect deployment status information to be displayed in the dashboard. The fix ensures that only successfully deployed production deployments are considered when determining the current production state.

## üì¶ infrastructure

### Improvements
- Increased deployment startup timeout to improve reliability: Extended deployment startup timeout from 3 minutes to 20 minutes to prevent deployment failures during slow image pulls or resource provisioning. This reduces failed deployments and improves overall platform reliability for users.


